# SF-1 — Scraper-Matrix (Stand: 2025-11-01)

## 1. Parser im Repo
| Seedbank / Quelle | Parser-Datei                                        | Test vorhanden | Zuletzt geprüft | Bemerkung         |
|-------------------|------------------------------------------------------|----------------|-----------------|-------------------|
| (Generic List)    | apps/price-service/src/parsers/list.ts               | nein           |                 | Listenseiten      |
| Zamnesia          | apps/price-service/src/parsers/zamnesia.ts           | nein           |                 | Shop „Zamnesia“   |

## 2. Geplante Parser
| Seedbank / Quelle | Geplanter Dateiname                                  | Priorität | Bemerkung           |
|-------------------|------------------------------------------------------|-----------|----------------------|
| Royal Queen Seeds | apps/price-service/src/parsers/royalqueenseeds.ts    | hoch      | viele Sorten         |
| Seed City         | apps/price-service/src/parsers/seedcity.ts           | mittel    | gutes Preis-Spektrum |
| Dutch Passion     | apps/price-service/src/parsers/dutchpassion.ts       | mittel    | Klassiker            |

## 3. Tests (sollen angelegt werden)
- `apps/price-service/tests/list.spec.ts`
- `apps/price-service/tests/zamnesia.spec.ts`

## 4. K8s-Scraper-Runtime
Diese Manifeste gehören zur Ausführung der Scraper im Cluster und müssen mitgeführt werden:
- `k8s/scraper/configmap.yaml`
- `k8s/scraper/cronjob-watchdog.yaml`
- `k8s/scraper/deployment-worker.yaml`
- `k8s/scraper/hpa.yaml`
- `k8s/scraper/service-metrics.yaml`
- `k8s/scraper/service-monitor.yaml`
- `k8s/scraper/networkpolicy.yaml`
- `k8s/scraper/pdb.yaml`
- `k8s/scraper/reliability.ym` *(prüfen, Schreibfehler?)*

## 5. Nächste Aktion
- Tests für `list.ts` und `zamnesia.ts` schreiben.
- Tabelle regelmäßig aktualisieren, wenn neue Parser entstehen.
# Scraper Guide

## Prinzipien
- robots.txt respektieren (MinimalÃ¢â‚¬â€˜Check enthalten). Keine CaptchaÃ¢â‚¬â€˜Umgehung.
- Niedrige RequestÃ¢â‚¬â€˜Rate, kurze Pausen zwischen Seiten (sleep 1Ã¢â‚¬â€œ2 s+).
- Selektoren versionieren. Bei 0 Treffern Alarm im Log.

## Neues AdapterÃ¢â‚¬â€˜Modul anlegen
1) Datei unter `src/adapters/<partner>.ts` erstellen.
2) `seedbank`, `startUrl`, `run(page)` implementieren.
3) In `index.ts` in `pickAdapter` & `targetToOrigin` registrieren.
4) K8s CronJob YAML kopieren, TARGET anpassen.

## Normalisierung
- `NormalizedPrice`: name, seedbank, price(EUR), currency.
- Gruppierung pro Strain Ã¢â€ â€™ `currentPrices[]` fÃƒÂ¼r DBÃ¢â‚¬â€˜Upsert.

## Persistenz
- Upsert setzt `currentPrices` und `lastUpdated` auf `now`.
- Optionaler Verlauf: zusÃƒÂ¤tzlich `priceHistory` im Backend pflegen.

## Fehlerbehandlung
- Sammlung in `errors[]`, Ausgabe im Log.
- Bei HTTP 403/429 Job abbremsen (Schedule/Delay erhÃƒÂ¶hen) und Adapter prÃƒÂ¼fen.
# SFâ€‘1 Scraperâ€‘Reliability


Ziel: Ausfallsichere, idempotente Scrapes mit Backoffâ€‘Retry, Deduplikation, Locking, Deadâ€‘Letter, Metriken und Selfâ€‘Heal.


Komponenten
- Mongo Jobâ€‘Queue (`scraper.jobs`) mit ZustÃ¤nden: queued, running, done, failed, dead.
- Uniquenessâ€‘Key: `source + seedId + variant + day` zur Deduplikation.
- Exponentielles Retry mit Jitter, Maxâ€‘Attempts = 5.
- Leaseâ€‘Lock per `leaseUntil` + Heartbeat. Orphanâ€‘Requeue nach Timeout.
- Deadâ€‘Letter nach Maxâ€‘Attempts.
- Metriken Ã¼ber Prometheus (/metrics): job_counts, durations, failures, retries.
- Healthâ€‘Endpoint: `/health/scraper` mit Detailstatus und jÃ¼ngsten Fehlern.
- Watchdogâ€‘CronJob: rÃ¤umt hÃ¤ngen gebliebene Jobs auf.
- K8s: Deployment Worker, HPA, PDB, NetworkPolicy, ServiceMonitor.


Idempotenz
- Upsert ins Ziel (Preise) per eindeutiger SchlÃ¼ssel (source, seedId, variant, date).
- Jobâ€‘Uniqâ€‘Index verhindert Doppelanlage.


Sicherheit
- Keine Secrets im Code. DBâ€‘Creds via vorhandenen Sealed Secrets.
# Runbook: Scraperâ€‘Reliability


Checks
- `GET /health/scraper` liefert ZustÃ¤nde und letzte Deadâ€‘Jobs.
- Prometheus: `sf1_scraper_jobs{state="failed"}` beobachten.
- Watchdog Cron lÃ¤uft alle 5 Minuten.


StÃ¶rungen
- Hohe Failâ€‘Rate: Parser prÃ¼fen, Zeitouts erhÃ¶hen, Backoff anpassen.
- Deadâ€‘Queue > 0: Ursachenanalyse je Quelle, ggf. Blocken der Quelle.


Wiederherstellung
- Selfâ€‘Heal Job starten (siehe Script) oder Cron abwarten.
