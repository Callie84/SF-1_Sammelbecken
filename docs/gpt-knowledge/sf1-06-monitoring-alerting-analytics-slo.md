# SF-1 — Monitoring & Alerting (Stand: 2025-11-01)

## 1. Namespace
- Alle Monitoring-Komponenten laufen im Namespace **monitoring**.
- Namespace-Manifest: `k8s/monitoring/00-namespace.yaml`

## 2. Logging / Metriken
- Loki: `k8s/monitoring/10-loki-configmap.yaml`, `11-loki-statefulset.yaml`, `12-loki-service.yaml`
- Promtail (Logs einsammeln): `k8s/monitoring/20-promtail-configmap.yaml`, `21-promtail-daemonset.yaml`
- Prometheus (Metriken): `k8s/monitoring/30-prometheus-configmap...` bis `32-prometheus-service.yaml`
- Recording/Rules: `k8s/monitoring/33-prometheus-rules-config...`, `34-prometheus-rules-watchdog...`
- SLO: `k8s/monitoring/slo-alerts.yml`, `k8s/monitoring/slo-recording-rules.yml`

## 3. Visualisierung
- Grafana Deployment: `k8s/monitoring/42-grafana-deployment.yaml`
- Grafana Service: `k8s/monitoring/43-grafana-service.yaml`
- Grafana Ingress: `k8s/monitoring/44-grafana-ingress.yaml`
- Dashboards/Datasources: `k8s/monitoring/40-grafana-datasources.yaml`, `41-grafana-dashboards.yaml`

## 4. Alerts
- Alertmanager Config: `k8s/monitoring/50-alertmanager-config...`
- Alertmanager Deployment/Service/Ingress: `51-...`, `52-...`, `53-...`
- Empfänger siehe: `docs/alerting-receivers.md` und `docs/alerts-receivers.md`
- Ziel: Ausfälle von backend, price-service, scraper und backup melden

## 5. Überwachte SF-1-Dienste
- Backend: `k8s/backend.yaml`
- Frontend: `k8s/frontend.yaml`
- Price-Service: `k8s/price-service.yaml`
- Scraper: alle `k8s/scraper/*`
- Backup-Jobs: `k8s/backup/*`
- Analytics/Plausible: `k8s/analytics/*` (optional)

## 6. Nächste Aktion
- Alert-Empfänger mit realen Mails/Webhooks ergänzen
- Grafana-URL im Projekt-Doku festhalten
# Alertmanager Receiver (EÃ¢â‚¬â€˜Mail + Slack)

## Ziele
- Kritische Alerts Ã¢â€ â€™ Slack + EÃ¢â‚¬â€˜Mail
- Warnungen Ã¢â€ â€™ EÃ¢â‚¬â€˜Mail
- Watchdog feuert dauerhaft (Heartbeat) Ã¢â€ â€™ bestÃƒÂ¤tigt Pipeline

## EmpfÃƒÂ¤nger
- Slack: `#alerts` via Incoming Webhook
- EÃ¢â‚¬â€˜Mail: `ops@seedfinderpro.de`

## Sicherheit
- Komplette AlertmanagerÃ¢â‚¬â€˜Konfiguration liegt als **Secret** (`alertmanager-config-secret`) vor, nicht als ConfigMap.
- SMTPÃ¢â‚¬â€˜Passwort befindet sich nur im Secret.

Status: Fertig. Kein Rollout in diesem Schritt.
NÃƒÂ¤chste Aktion: SpÃƒÂ¤ter `scripts/alerting-receiver-deploy.ps1` ausfÃƒÂ¼hren.
# Alertmanager Receiver

## Routing
- `severity=critical` Ã¢â€ â€™ EÃ¢â‚¬â€˜Mail + Telegram
- `severity=warning`  Ã¢â€ â€™ Slack
- Default Ã¢â€ â€™ EÃ¢â‚¬â€˜Mail

## Annahmen
- SMTP: mailbox.org (Beispiel). Ersetze bei Bedarf Server/Absender.
- Telegram: Bot + Channel/Chat vorhanden.
- Slack: Incoming Webhook aktiv.

## Test
- `scripts/alerts-send-test.ps1 -Type critical`
- `scripts/alerts-send-test.ps1 -Type warning`

Status: Fertig. Keine AusfÃƒÂ¼hrung bis GoÃ¢â‚¬â€˜Live.
NÃƒÂ¤chste Aktion: Falls abweichende Provider genutzt werden, Werte in YAML anpassen.
# Analytics (Plausible selfÃ¢â‚¬â€˜hosted)

## Events
- `search_performed { term_len, results }`
- `seed_view { seedId }`
- `affiliate_click { partner }`

## Dashboards
- TopÃ¢â‚¬â€˜Seeds, TopÃ¢â‚¬â€˜Flows, ExitÃ¢â‚¬â€˜Pages

## Datenschutz
- IP anonymisiert, keine Cookies, OptÃ¢â‚¬â€˜Out Link bereitstellen

## Integration
- Frontend: sendet Events via `fetch("/api/analytics")`
- Backend: leitet anonymisiert an Plausible weiter
- Ingress: eigener Subdomain `analytics.seedfinderpro.de`

## Umgebungsvariablen
- PLAUSIBLE_URL
- PLAUSIBLE_SECRET
- ANALYTICS_MODE=plausible
- CONSENT_REQUIRED=true

## Wartung
- Backup der Plausible-DB tÃ¤glich via `sf1-backup`
- Alerts bei HTTP 5xx in `analytics` Namespace

## CMP
- ConsentModal prÃ¼ft `sf1_consent` in `localStorage`
- Ohne Zustimmung keine Event-Sendungen
# Plausible Betrieb

## Erstkonfiguration
1) `kubectl apply -f k8s/analytics/*.yaml` in Reihenfolge: namespace Ã¢â€ â€™ postgres Ã¢â€ â€™ clickhouse Ã¢â€ â€™ plausible Ã¢â€ â€™ ingress
2) Ãƒâ€“ffne https://analytics.seedfinderpro.de und lege die Site `seedfinderpro.de` an.
3) PrÃƒÂ¼fe, dass `/js/script.js` unter https://seedfinderpro.de/js/script.js geladen wird.

## Backups
- Postgres: StandardÃ¢â‚¬â€˜PVC Ã¢â€ â€™ CronJob fÃƒÂ¼r `pg_dump` optional ergÃƒÂ¤nzen
- ClickHouse: Volume Snapshot; optional S3Ã¢â‚¬â€˜Backup per clickhouseÃ¢â‚¬â€˜backup Tool

## Monitoring
- Health: `GET /` der plausibleÃ¢â‚¬â€˜Service (HTTP 200)
- Logs: `kubectl logs deploy/plausible -n analytics`

## Sicherheit
- AdminÃ¢â‚¬â€˜Registrierung per `DISABLE_REGISTRATION=true` blockiert
- Zugriff auf UI ggf. mit BasicAuthÃ¢â‚¬â€˜Middleware schÃƒÂ¼tzen (Traefik)
# SLO/SLI Ã¢â‚¬â€ Definitionen

## Begriffe
- **SLI**: MessgrÃƒÂ¶ÃƒÅ¸e, z.Ã¢â‚¬Â¯B. Fehlerrate oder Latenz.
- **SLO**: Zielwert, z.Ã¢â‚¬Â¯B. Fehlerrate Ã¢â€°Â¤ 0,1Ã¢â‚¬Â¯%.
- **Error Budget**: 100Ã¢â‚¬Â¯% Ã¢Ë†â€™ SLO, z.Ã¢â‚¬Â¯B. 0,1Ã¢â‚¬Â¯% Ausfall erlaubt in 30 Tagen.

## SFÃ¢â‚¬â€˜1 SLI
1. **API Fehlerrate**: Anteil `status_code>=500` an allen Requests.
2. **API Latenz**: p95/p99 von `http_request_duration_seconds`.
3. **Extern VerfÃƒÂ¼gbarkeit**: Anteil `probe_success==1`.

## SLO
- Fehlerrate Ã¢â€°Â¤ 0,1Ã¢â‚¬Â¯% auf 30 Tage.
- p95 Ã¢â€°Â¤ 300Ã¢â‚¬Â¯ms (5 Min), p99 Ã¢â€°Â¤ 600Ã¢â‚¬Â¯ms (5 Min).
- VerfÃƒÂ¼gbarkeit Ã¢â€°Â¥ 99,9Ã¢â‚¬Â¯% auf 30 Tage.

## Visualisierung
- GrafanaÃ¢â‚¬â€˜Dashboard `sf1-slo-overview` zeigt SLIs, Error Budget, Burn Rate und Latenzen.

## Betrieb
- Ãƒâ€nderungen am SLO in `slo-recording-rules.yml` anpassen, Dashboard passt sich an.

## Status & NÃƒÂ¤chste Aktion
**Status:** Definitionen und Artefakte bereit.  
**NÃƒÂ¤chste Aktion:** PrometheusÃ¢â‚¬â€˜Rules & Alerts anwenden, Dashboard importieren.
